\chapter{Scene Recognition}
In this chapter, we discuss the process of how a scene is recognized by detected events in the clip. 
This chapter includes the issue mining scene-event relations from downloaded script data.
Then a segmenter algorithm is used to segment audio data for event detection. 
In the last, the detected event sequence is used for scene recognition. 

\section{Scene-Event Relation Mining}

%\subsection{Event TF-IDF Calculation}
In order to calculate how important a audible event is in identifing a scene, we need a metric for calculating event distinctiveness. 
It is not enough if we only use the event happening frequency as a single metric for this distinctiveness. 
Because if events are ranked this way, common events which happen frequently in many scenes would rank high and bring no effect for recognizing different scenes. 
To tackle this issue, Term Frequency-Inverse Document Frequency (TF-IDF) statistic is used for calculating event distinctiveness. \\ 

The original TF-IDF statistic is used to reflect how important a word is to a document in a corpus. 
We use the idea of TF-IDF statistic, but applied to our special case. 
In our case, the corpus refers to the all the context files, each contains one scene. 
Document is therefore one scene, and is comprised of all the context files that have been attributed to that scene. 
Word here means an audible event. 
Suppose $e$ and $s$ represent a event and a scene, respectively. 
$f(e,s)$ denotes the number of context that e has appeared in it among all the contexts that belong to scene $s$.  
$C$ denotes the number of all contexts regardless of scenes. 
Hence TF and IDF are calculated as: 
\begin{equation}
\begin{split}
 TF &= 1 + \log{f(e,s)} \\ 
 IDF &= 1 + \log{\frac{C}{f(e,s)}}
\end{split}
\end{equation} 

\section{Audio Segmentation}
Once the models are built, we are ready to use it to test on a potential event clip. 
But for the problem of scene recognition, we need to detect the events happening in a clip, therefore, a audio segmentation technique is employed to segment audio clips. \\ 

There are lots of research carried out on the segmentation of audios.
Some may simply use the average frame energy as the threshold to cut the clips, while other complicated methods involve more features and even use machine learning techniques. 
In this project, we use a method of setting a threshold combining frame energy and spectral centroids, and this method is described in \cite{giannakopoulos2009method}.
This method uses two features from audio:
\begin{itemize}
\item{Frame Energy: this features depicts the overall energy level of one frame. Typically frames where there are some events happening have a higher energy than silent frames.}
\item{Spectral centroid: this represents the "center of gravity" of the audio spectrum. For example, the spectral centroid of the i-th frame (denoted by $ C_i$) is given by the equation:
\[
C_i = \frac{\sum\limits_{k=1}^Nk\times Amp(k)}{\sum\limits_{k=1}^NAmp(k)}
\]
}
\end{itemize}

In this equation, $Amp(k)$ is the amplitude corresponding to bin $k$ in Discrete Fourier Transform (DFT) spectrum. 
So a higher spectral centroid denotes a higher frequency in this frame. Because noises are often in a low frequency, we could use this feature to filter them out. 

\section{Scene Inference}
Once a event sequence is detected, we use that sequence of events to infer the scene we think it's the most likely one. 
After event detection on a segment of testing audio clip, we could get posterior scores for different event models. 
We use the posteriors as the likelyhood for events. The highest ranked event may be the most likely one. \\ 

Sometimes, one segment may contain multiple events overlapping together. 
So in this case, only using the top 1 detected events is not enough. 
So we use the top 3 detected events for each segment, and their posteriors are used as weight. 
After multipling with the TF-IDF scores of each event to each scene, we could get a score for every scene. 
Then the highest scored scene are choosen as the recognized scene. 

\section{Summary}
