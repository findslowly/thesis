\chapter{Related Works}
\section{Audible Events Taxonomy}
Audible events are a concept hard to define, especially for the detailed sound sources. 
Researchers have long been researching the area of the automatic classification of environmental sound. 
But the researches toward an audible event taxonomy differs a lot from each other. 

An early taxonomy for environment sounds was proposed by Schafer \et \cite{schafer1993soundscape}. which divides sounds into six broad categories: natural, human, society, mechanical, silence and indicators. 
Gaver \et \cite{gaver1993world} take an ecological approach to everyday listening. 
He defined basic level events by the simple interactions from a physical perspective. 
For example, he first distinguish everyday sound-producing events by their broad classes of materials. 
The three material classes he used is virating objects, aerodynamics sounds, and liquid sounds. 
Gaver then divided these objects by the iteractions that can cause them to sound, like impacts, scraping, explosion, splashing, etc. 
We think that although Gaver's research are very detail in the construction of events from iteractions of materials, but it is not suitable for detecting general events in our case. 
Since we are doing event detection for scene recognition, the events need to general to accomdate unknown scenes. 
 
Brown \et \cite{brown2011towards} proposed a more detailed taxonomy by dividing the large acoustic environment into indoor and outdoor environment. 
In the outdoor environment, there are four acoustic categories: urban, rural, wilderness and underwater. 
The contribution in their work is to present a sound source structure that is the same for any environments. 
For a single environment, sounds are splitted by generated by human activity or not. 
The human part is then divided by transport, human movement, mechanical, etc. 
The non-human part is further grouped by nature and domesticated animals. 
Their work provide a clear structure for others to follow, but has a disadvantage of being not specific enough. 

Salamon \et \cite{salamon2014dataset} focuses on the urban sound taxonomy, and proposed a detailed sound event taxonomy under the context of urban environment\footnote{\url{https://serv.cusp.nyu.edu/projects/urbansounddataset/taxonomy.html}}. 
In his method, he tries to construct in the following three requirements. 
First, the taxonomy should be easily combined with previous research.
Second, it need to be as detailed as possible. 
The taxonomy should go down to the low-level audible events, instead of staying on some broad sound classes. 
Third, he focuses on the sound relevant to urban environment, such as those sound sources that contribute to noise pollution. 
Under these requirements, he proposed a urban sound taxonomy\footnote{\url{https://serv.cusp.nyu.edu/projects/urbansounddataset/urban\_sound\_taxonomy\_v05.pdf}} containing 54 basic sound events. 
The requirement and taxonomy proposed in Salamon's paper is really helpful for our process of building a taxonomy. 
We more or less take the taxonomy he created into account, especially the categorization in broad-level sounds. 

\section{Audio Event Detection}
There are some early research on the event classification in everyday life, which focuses on some predefined sounds. 
For example, Fagerlund \et \cite{fagerlund2007bird} used SVM to classify bird species. 
Mel-cepstrum parameters and a set of low-level signal parameters are used for their features. 
Another research has been done on battlefield ground vehicles. And they proposed fuzzy logic rule-based classifiers (FLRBC) as their architecture \cite{wu2007classification}. 
In addition to these research, some studies have been carried out on a low number of sound categories in one or two audio context. 
Chen \et \cite{chen2005bathroom} propose a system for automated bathroom activity monitoring. 
They mainly use MFCC features in HMM, and claimed for an accuracy rate for most sound categories above $84\%$. 
Another research on kitchen environment has been done by Kraft \cite{kraft2005temporal}. 
They proposed a feature extraction method using a temporal extension of Independent Component Analysis (ICA). 
But acoustic events in their research are confined in kitchen, like water boiling, sizzle sound, alarms, etc. 
Many of the previously mentioned methods are performing classification in a small size event lists, thus not applicable for automatic event detection in many other environments. 
 
An event detection challenge has been held in 2013. 
The event detection is a part of the challenge, which include scene detection and event detection.  
It is called IEEE AASP Challenge\footnote{\url{http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge}}. 
The goal of the event detection task was to detect 16 different events in the office environment. 
The organizer has indeed two tasks regarding to the event detection: one for monophonic event detection, and another for polyphonic event detection.  
The main metrics they used are the acoustic event error rate (AEER) \cite{giannoulis2013ieee} and the F-measure.
The highest performing system submitted to their evaluation has a frame-based accuracy of $61.52\%$. 
In this high-performing system, Schr\"{o}der \et \cite{schroder2013acoustic} proposed a HMM model on features extracted from Gabor filterbank combined with noise suppresion technique. 

\section{Audio Scene Detection}
In the area of audio scene recognition, most of the proposed scene recognition systems are directly modeling global acoustic features of the audio scene. 
Ma \et \cite{ma2006acoustic} proposed a HMM-based acoustic context classifier, which trained on data from 11 acoustic scenes in everyday life. 
The features they used are traditional MFCCs with velocity and acceleration, which resulted in a 39 dimension features. 

Cai \et \cite{cai03usingstrcture} has done a research on the similarity measure of audios. 
Their perspective is to model audio structures from the structure patterns. 
Those patterns refer to the temporal or spectral features. 
They mainly are pitch contour, harmonicity and energy envelope. 
Using these patterns, they avoid the problem of only utilizing averaged features. 

Lu \et \cite{lu2001robust} proposed a algorithm for classifying an audio into music, environment sound, speech and silence. 
In addition to the general used features like zero-crossing rate ratio and spectrum flux, they also include some new features. 
Then they used a K-Nearest-Neighbor (KNN) to function as a classifier. 
In their experiment, their total accuracy rate is over 96$\%$. 
Yet for their work, the audio classes considered is really limited, and not suitable for real life audio scene classification problem.  

% paraphrase!
Giannoulis \et \cite{giannoulis2013applications} described the on acoustic scene classification and sound events detection.  
In the scene classification part, there are 10 different scenes to classify. 
Roma \et \cite{romarecurrence} use Recurrence Quantificaton Analysis (RQA) and MFCC features outperforming other systems when using a standard SVM classifer. 

One of the approaches to consider audio events in scene recognition is introduced by Cai \et \cite{cai2006flexible}. 
They proposed a flexible framework to recognize 5 audio context using 10 predifined events. 
The main models they used are HMM, Grammar Network, and Bayesian Network. 
Another event-based audio context recognition is proposed by Heittola \et \cite{heittola2010audio}. 
They build histograms for each scene with a set of predifined audio events, and calcuate the cosine distance of the histograms with a new histogram of detected events.\\

